{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8673b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40142f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('my_data.csv')\n",
    "X_data_pd = train_data[['x2', 'y2']]\n",
    "Y_data_pd = train_data[['q1', 'q2']]\n",
    "\n",
    "X_data = X_data_pd.to_numpy()\n",
    "Y_data = Y_data_pd.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21ea3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1500\n",
      "Validation set size: 500\n",
      "Test set size: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(\n",
    "    X_data, Y_data, test_size=500, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_temp, Y_temp, test_size=500, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")   \n",
    "print(f\"Validation set size: {X_val.shape[0]}\")         \n",
    "print(f\"Test set size: {X_test.shape[0]}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f881bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dbf6d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">642</span> (2.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m642\u001b[0m (2.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">642</span> (2.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m642\u001b[0m (2.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3217 - val_loss: 0.2022\n",
      "Epoch 2/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2083 - val_loss: 0.1911\n",
      "Epoch 3/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1971 - val_loss: 0.1907\n",
      "Epoch 4/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2037 - val_loss: 0.1888\n",
      "Epoch 5/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1953 - val_loss: 0.1902\n",
      "Epoch 6/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1946 - val_loss: 0.1912\n",
      "Epoch 7/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1931 - val_loss: 0.1878\n",
      "Epoch 8/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2009 - val_loss: 0.1898\n",
      "Epoch 9/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1884 - val_loss: 0.1881\n",
      "Epoch 10/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2030 - val_loss: 0.1880\n",
      "Epoch 11/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1989 - val_loss: 0.1873\n",
      "Epoch 12/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1897 - val_loss: 0.1875\n",
      "Epoch 13/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1953 - val_loss: 0.1876\n",
      "Epoch 14/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2024 - val_loss: 0.1882\n",
      "Epoch 15/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2001 - val_loss: 0.1910\n",
      "Epoch 16/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1912 - val_loss: 0.1877\n",
      "Epoch 17/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1877 - val_loss: 0.1872\n",
      "Epoch 18/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1872 - val_loss: 0.1872\n",
      "Epoch 19/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1818 - val_loss: 0.1881\n",
      "Epoch 20/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1909 - val_loss: 0.1871\n",
      "Epoch 21/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1958 - val_loss: 0.1874\n",
      "Epoch 22/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1896 - val_loss: 0.1878\n",
      "Epoch 23/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1938 - val_loss: 0.1876\n",
      "Epoch 24/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1921 - val_loss: 0.1872\n",
      "Epoch 25/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1943 - val_loss: 0.1873\n",
      "Epoch 26/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1980 - val_loss: 0.1875\n",
      "Epoch 27/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1966 - val_loss: 0.1877\n",
      "Epoch 28/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1890 - val_loss: 0.1874\n",
      "Epoch 29/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2006 - val_loss: 0.1871\n",
      "Epoch 30/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1856 - val_loss: 0.1869\n",
      "Epoch 31/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1854 - val_loss: 0.1876\n",
      "Epoch 32/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1953 - val_loss: 0.1886\n",
      "Epoch 33/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1937 - val_loss: 0.1867\n",
      "Epoch 34/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1910 - val_loss: 0.1886\n",
      "Epoch 35/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1889 - val_loss: 0.1873\n",
      "Epoch 36/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1953 - val_loss: 0.1870\n",
      "Epoch 37/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1904 - val_loss: 0.1872\n",
      "Epoch 38/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1971 - val_loss: 0.1876\n",
      "Epoch 39/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1884 - val_loss: 0.1875\n",
      "Epoch 40/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2021 - val_loss: 0.1882\n",
      "Epoch 41/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1964 - val_loss: 0.1874\n",
      "Epoch 42/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1975 - val_loss: 0.1876\n",
      "Epoch 43/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2015 - val_loss: 0.1872\n",
      "Epoch 44/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1977 - val_loss: 0.1870\n",
      "Epoch 45/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1873 - val_loss: 0.1869\n",
      "Epoch 46/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1986 - val_loss: 0.1883\n",
      "Epoch 47/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2000 - val_loss: 0.1882\n",
      "Epoch 48/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1956 - val_loss: 0.1875\n",
      "Epoch 49/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1884 - val_loss: 0.1873\n",
      "Epoch 50/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1955 - val_loss: 0.1871\n",
      "Epoch 51/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1824 - val_loss: 0.1868\n",
      "Epoch 52/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1966 - val_loss: 0.1875\n",
      "Epoch 53/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1998 - val_loss: 0.1879\n",
      "Epoch 54/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1886 - val_loss: 0.1888\n",
      "Epoch 55/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2010 - val_loss: 0.1871\n",
      "Epoch 56/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1948 - val_loss: 0.1867\n",
      "Epoch 57/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1831 - val_loss: 0.1898\n",
      "Epoch 58/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1893 - val_loss: 0.1872\n",
      "Epoch 59/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1911 - val_loss: 0.1887\n",
      "Epoch 60/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1974 - val_loss: 0.1861\n",
      "Epoch 61/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1947 - val_loss: 0.1864\n",
      "Epoch 62/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1941 - val_loss: 0.1867\n",
      "Epoch 63/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1903 - val_loss: 0.1864\n",
      "Epoch 64/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2006 - val_loss: 0.1886\n",
      "Epoch 65/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1856 - val_loss: 0.1862\n",
      "Epoch 66/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1848 - val_loss: 0.1862\n",
      "Epoch 67/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1949 - val_loss: 0.1859\n",
      "Epoch 68/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1972 - val_loss: 0.1852\n",
      "Epoch 69/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1823 - val_loss: 0.1853\n",
      "Epoch 70/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1826 - val_loss: 0.1857\n",
      "Epoch 71/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1908 - val_loss: 0.1861\n",
      "Epoch 72/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1918 - val_loss: 0.1865\n",
      "Epoch 73/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1906 - val_loss: 0.1857\n",
      "Epoch 74/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1922 - val_loss: 0.1858\n",
      "Epoch 75/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1891 - val_loss: 0.1851\n",
      "Epoch 76/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1866 - val_loss: 0.1864\n",
      "Epoch 77/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1956 - val_loss: 0.1862\n",
      "Epoch 78/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1923 - val_loss: 0.1857\n",
      "Epoch 79/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1854 - val_loss: 0.1859\n",
      "Epoch 80/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2025 - val_loss: 0.1857\n",
      "Epoch 81/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1915 - val_loss: 0.1849\n",
      "Epoch 82/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1935 - val_loss: 0.1851\n",
      "Epoch 83/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1863 - val_loss: 0.1855\n",
      "Epoch 84/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1907 - val_loss: 0.1865\n",
      "Epoch 85/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 86/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1976 - val_loss: 0.1864\n",
      "Epoch 87/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1878 - val_loss: 0.1849\n",
      "Epoch 88/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1928 - val_loss: 0.1870\n",
      "Epoch 89/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1883 - val_loss: 0.1849\n",
      "Epoch 90/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1976 - val_loss: 0.1887\n",
      "Epoch 91/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1960 - val_loss: 0.1853\n",
      "Epoch 92/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1899 - val_loss: 0.1844\n",
      "Epoch 93/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1806 - val_loss: 0.1841\n",
      "Epoch 94/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1867 - val_loss: 0.1842\n",
      "Epoch 95/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1945 - val_loss: 0.1862\n",
      "Epoch 96/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1970 - val_loss: 0.1865\n",
      "Epoch 97/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1958 - val_loss: 0.1863\n",
      "Epoch 98/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1937 - val_loss: 0.1841\n",
      "Epoch 99/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1890 - val_loss: 0.1872\n",
      "Epoch 100/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1834 - val_loss: 0.1841\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(2,)),  # Input: x2, y2\n",
    "    Dense(2)  # Output: q1, q2 (linear)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, Y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f3d7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "True: [0.94034066 0.14959965], Predicted: [0.8566648  0.36990294]\n",
      "True: [-0.82279808 -0.10685689], Predicted: [-0.94302607  0.06856968]\n",
      "True: [-0.82279808 -0.14959965], Predicted: [-0.96001023  0.05800574]\n",
      "True: [0.40605619 0.87622652], Predicted: [0.6187808  0.30473036]\n",
      "True: [0.40605619 0.23508516], Predicted: [ 0.5713296  -0.10221819]\n",
      "True: [-0.60908429 -0.49154171], Predicted: [-0.90463215  0.06242318]\n",
      "True: [0.19234241 0.27782792], Predicted: [ 0.37601018 -0.09009377]\n",
      "True: [-1.35708254  1.00445479], Predicted: [-0.83943707  0.01058397]\n",
      "True: [ 0.94034066 -0.66251274], Predicted: [0.5759019  0.01398008]\n",
      "True: [0.03205707 1.04719755], Predicted: [0.46489698 0.06107192]\n",
      "True: [-0.44879895 -0.66251274], Predicted: [-0.82118934  0.05995099]\n",
      "True: [ 0.88691221 -0.87622652], Predicted: [ 0.43049532 -0.04670803]\n",
      "True: [-0.34194206 -0.27782792], Predicted: [-0.48945397 -0.02281316]\n",
      "True: [ 0.08548551 -0.10685689], Predicted: [ 0.04547047 -0.03289431]\n",
      "True: [-0.5022274  -0.49154171], Predicted: [-0.79633117  0.04824699]\n",
      "True: [-0.71594118 -0.27782792], Predicted: [-0.91861516  0.07340389]\n",
      "True: [-0.82279808  0.14959965], Predicted: [-0.8110514   0.05313548]\n",
      "True: [-1.25022565  0.32057068], Predicted: [-1.080489   -0.05610753]\n",
      "True: [-1.46393943 -0.70525549], Predicted: [-1.459336  -0.7662051]\n",
      "True: [-1.41051099 -0.10685689], Predicted: [-1.3468868  -0.33323428]\n",
      "True: [-0.3953705   0.70525549], Predicted: [-0.04712874 -0.01830521]\n",
      "True: [-0.55565584 -0.44879895], Predicted: [-0.8385948   0.06640997]\n",
      "True: [-0.98308342  0.66251274], Predicted: [-0.66039914 -0.00364806]\n",
      "True: [0.35262775 1.00445479], Predicted: [0.58175087 0.34780693]\n",
      "True: [ 0.88691221 -0.91896928], Predicted: [ 0.40895933 -0.05158472]\n",
      "True: [ 0.61976998 -0.32057068], Predicted: [ 0.5035783  -0.10890757]\n",
      "True: [-0.82279808  0.02137138], Predicted: [-0.8858164   0.08113025]\n",
      "True: [ 0.24577085 -0.19234241], Predicted: [ 0.17418405 -0.04491616]\n",
      "True: [-0.23508516  0.06411414], Predicted: [-0.2058428  -0.02561249]\n",
      "True: [-1.08994031 -0.61976998], Predicted: [-1.2422383  -0.32917765]\n",
      "True: [-0.12822827  0.14959965], Predicted: [-0.04949465 -0.02574775]\n",
      "True: [ 0.78005532 -0.91896928], Predicted: [ 0.31422096 -0.05460794]\n",
      "True: [-0.02137138 -0.06411414], Predicted: [-0.04915275 -0.02606729]\n",
      "True: [0.13891396 0.66251274], Predicted: [ 0.4786858  -0.06776158]\n",
      "True: [ 0.13891396 -0.27782792], Predicted: [ 0.00851396 -0.02883324]\n",
      "True: [-0.28851361 -0.10685689], Predicted: [-0.35061616 -0.02657882]\n",
      "True: [-0.3953705   0.49154171], Predicted: [-0.1505015  -0.02155694]\n",
      "True: [-0.71594118  0.10685689], Predicted: [-0.69832975  0.00650611]\n",
      "True: [0.67319843 0.61976998], Predicted: [0.7691563  0.38261053]\n",
      "True: [-1.14336875  0.02137138], Predicted: [-1.1101032  -0.09482732]\n",
      "True: [-0.28851361  0.87622652], Predicted: [ 0.14367715 -0.02448134]\n",
      "True: [-0.34194206  0.02137138], Predicted: [-0.3397159  -0.02668052]\n",
      "True: [0.35262775 0.57702722], Predicted: [0.60423607 0.03112519]\n",
      "True: [-0.71594118  0.02137138], Predicted: [-0.7573237  0.0298168]\n",
      "True: [-0.3953705  -0.40605619], Predicted: [-0.6109057  -0.01543962]\n",
      "True: [-1.14336875  0.32057068], Predicted: [-1.0137401   0.01498746]\n",
      "True: [-0.98308342  0.06411414], Predicted: [-1.0022895  0.0351289]\n",
      "True: [ 0.24577085 -0.96171204], Predicted: [-0.23691456 -0.01633616]\n",
      "True: [-1.30365409  0.53428446], Predicted: [-1.0312629  -0.03159172]\n",
      "True: [1.04719755 0.96171204], Predicted: [1.0105764 0.8983298]\n",
      "True: [-0.5022274  -0.70525549], Predicted: [-0.8826661   0.04495714]\n",
      "True: [-1.30365409  0.44879895], Predicted: [-1.0649333  -0.05515102]\n",
      "True: [-1.1967972  -0.44879895], Predicted: [-1.2866336  -0.32292458]\n",
      "True: [ 0.72662687 -1.00445479], Predicted: [ 0.21029298 -0.02803725]\n",
      "True: [-1.25022565 -1.00445479], Predicted: [-1.3202283  -0.70843786]\n",
      "True: [-0.60908429 -0.87622652], Predicted: [-0.99206245 -0.07292654]\n",
      "True: [ 0.35262775 -0.19234241], Predicted: [ 0.29894334 -0.07331167]\n",
      "True: [0.72662687 0.02137138], Predicted: [0.70250946 0.08084521]\n",
      "True: [-1.46393943  0.61976998], Predicted: [-1.0750289  -0.15712133]\n",
      "True: [1.04719755 0.14959965], Predicted: [0.90077853 0.49713406]\n",
      "True: [-1.08994031  0.96171204], Predicted: [-0.5883035  -0.01144193]\n",
      "True: [-0.76936963  0.19234241], Predicted: [-0.71201044  0.01167114]\n",
      "True: [ 0.9937691  -0.83348377], Predicted: [0.5249255  0.02311555]\n",
      "True: [-0.12822827  0.79074101], Predicted: [ 0.27585745 -0.05211707]\n",
      "True: [-0.07479983 -0.91896928], Predicted: [-0.51654524 -0.01438063]\n",
      "True: [ 0.40605619 -0.06411414], Predicted: [ 0.42578277 -0.10414749]\n",
      "True: [-0.3953705   0.19234241], Predicted: [-0.30619374 -0.02630845]\n",
      "True: [ 0.45948464 -0.91896928], Predicted: [-0.01148053 -0.01520316]\n",
      "True: [-0.3953705  -0.57702722], Predicted: [-0.7095908   0.01225602]\n",
      "True: [ 0.19234241 -0.70525549], Predicted: [-0.16278924 -0.01856782]\n",
      "True: [-0.60908429 -0.61976998], Predicted: [-0.94372135  0.0241931 ]\n",
      "True: [0.88691221 0.91896928], Predicted: [0.8933236 0.7998768]\n",
      "True: [-0.44879895  0.87622652], Predicted: [-0.02023972 -0.01584337]\n",
      "True: [ 0.24577085 -0.14959965], Predicted: [ 0.20018043 -0.05164636]\n",
      "True: [0.45948464 0.02137138], Predicted: [ 0.52528745 -0.11879078]\n",
      "True: [-0.34194206 -0.10685689], Predicted: [-0.4047875  -0.02610699]\n",
      "True: [0.61976998 0.06411414], Predicted: [ 0.6593409  -0.00902327]\n",
      "True: [-1.25022565  0.87622652], Predicted: [-0.8253611   0.04375438]\n",
      "True: [0.56634153 0.19234241], Predicted: [0.66058296 0.00632603]\n",
      "True: [ 0.72662687 -1.04719755], Predicted: [ 0.18376793 -0.0209035 ]\n",
      "True: [-0.07479983  0.53428446], Predicted: [ 0.21238296 -0.04795738]\n",
      "True: [-1.57079633 -0.66251274], Predicted: [-1.5512097  -0.82798564]\n",
      "True: [0.83348377 0.66251274], Predicted: [0.8392454 0.5932288]\n",
      "True: [ 0.78005532 -1.04719755], Predicted: [ 0.23797993 -0.03132225]\n",
      "True: [0.19234241 0.02137138], Predicted: [ 0.23899598 -0.06159863]\n",
      "True: [-0.66251274  0.61976998], Predicted: [-0.3560148  -0.02322438]\n",
      "True: [0.56634153 0.70525549], Predicted: [0.7111115  0.33656716]\n",
      "True: [-1.35708254 -0.83348377], Predicted: [-1.3856496 -0.7124977]\n",
      "True: [0.83348377 0.57702722], Predicted: [0.83801657 0.5309049 ]\n",
      "True: [-0.28851361  0.53428446], Predicted: [-0.02002297 -0.02353528]\n",
      "True: [-0.92965497  0.53428446], Predicted: [-0.68335444  0.00219801]\n",
      "True: [-0.82279808 -0.57702722], Predicted: [-1.0656481  -0.10120968]\n",
      "True: [-0.92965497 -0.87622652], Predicted: [-1.1594368  -0.35327014]\n",
      "True: [-0.71594118 -0.32057068], Predicted: [-0.934905    0.06230797]\n",
      "True: [ 0.67319843 -0.44879895], Predicted: [ 0.48175848 -0.09971815]\n",
      "True: [-1.51736788  0.02137138], Predicted: [-1.3759335  -0.36791587]\n",
      "True: [ 0.94034066 -0.19234241], Predicted: [0.74919957 0.2024738 ]\n",
      "True: [0.35262775 0.40605619], Predicted: [ 0.58220613 -0.06932272]\n",
      "True: [-0.66251274 -0.19234241], Predicted: [-0.8235976   0.05870698]\n",
      "True: [-0.5022274  -0.91896928], Predicted: [-0.9318496  -0.02597578]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "for i in range(100):\n",
    "    print(f\"True: {Y_test[i]}, Predicted: {Y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7540fe95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# q1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplt\u001b[49m.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m plt.scatter(Y_test[:,\u001b[32m0\u001b[39m], Y_pred[:,\u001b[32m0\u001b[39m], alpha=\u001b[32m0.5\u001b[39m)\n\u001b[32m      4\u001b[39m plt.plot([Y_test[:,\u001b[32m0\u001b[39m].min(), Y_test[:,\u001b[32m0\u001b[39m].max()],\n\u001b[32m      5\u001b[39m          [Y_test[:,\u001b[32m0\u001b[39m].min(), Y_test[:,\u001b[32m0\u001b[39m].max()], \u001b[33m'\u001b[39m\u001b[33mr--\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# q1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Y_test[:,0], Y_pred[:,0], alpha=0.5)\n",
    "plt.plot([Y_test[:,0].min(), Y_test[:,0].max()],\n",
    "         [Y_test[:,0].min(), Y_test[:,0].max()], 'r--')\n",
    "plt.xlabel('True q1')\n",
    "plt.ylabel('Predicted q1')\n",
    "plt.title('q1 Prediction')\n",
    "\n",
    "# q2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(Y_test[:,1], Y_pred[:,1], alpha=0.5)\n",
    "plt.plot([Y_test[:,1].min(), Y_test[:,1].max()],\n",
    "         [Y_test[:,1].min(), Y_test[:,1].max()], 'r--')\n",
    "plt.xlabel('True q2')\n",
    "plt.ylabel('Predicted q2')\n",
    "plt.title('q2 Prediction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
